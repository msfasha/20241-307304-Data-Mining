{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **Introduction to Text Mining**\n",
    "\n",
    "**Text Mining**, also known as **Text Data Mining** or **Text Analytics**, refers to the process of extracting meaningful information and insights from unstructured text data. The goal is to convert text into numerical or structured formats that can be analyzed for patterns, relationships, and trends.\n",
    "\n",
    "**Applications of Text Mining**:\n",
    "- Sentiment analysis (e.g., determining whether a review is positive or negative).\n",
    "- Topic modeling (e.g., discovering topics in a set of documents).\n",
    "- Spam detection (e.g., classifying emails as spam or not spam).\n",
    "- Text classification and clustering (e.g., organizing articles into categories).\n",
    "- Information retrieval (e.g., search engines).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Key Techniques in Text Mining**\n",
    "\n",
    "1. **Text Preprocessing**: Preparing the text data for analysis by cleaning and transforming it.\n",
    "   - Tokenization\n",
    "   - Removing stop words\n",
    "   - Stemming and lemmatization\n",
    "   - Lowercasing, punctuation removal\n",
    "\n",
    "2. **Text Representation**: Converting text into a numerical representation.\n",
    "   - **Bag of Words (BoW)**: Represents text as the frequency of words in a document.\n",
    "   - **TF-IDF (Term Frequency-Inverse Document Frequency)**: Adjusts word frequency by accounting for how common a word is across multiple documents.\n",
    "   - **Word Embeddings**: Vector representations of words (e.g., Word2Vec, GloVe).\n",
    "\n",
    "3. **Text Classification**: Assigning predefined categories to documents using machine learning algorithms like Naive Bayes, SVM, or deep learning models.\n",
    "\n",
    "4. **Text Clustering**: Grouping similar documents into clusters without predefined labels (unsupervised learning).\n",
    "   - Algorithms like K-Means, DBSCAN, or hierarchical clustering.\n",
    "\n",
    "5. **Sentiment Analysis**: Analyzing the sentiment or emotional tone of text, commonly used in product reviews, social media analysis, etc.\n",
    "\n",
    "6. **Named Entity Recognition (NER)**: Identifying and classifying named entities (e.g., people, organizations, locations) in text.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Text Preprocessing Pipeline**\n",
    "\n",
    "Text preprocessing is an essential step in text mining. It involves transforming raw text into a format that can be used for further analysis. Here’s the typical text preprocessing pipeline:\n",
    "\n",
    "1. **Lowercasing**: Converting all characters to lowercase to avoid case-sensitive variations of the same word.\n",
    "2. **Tokenization**: Splitting text into individual words or tokens.\n",
    "3. **Stop Words Removal**: Removing common words (e.g., \"is,\" \"the,\" \"and\") that do not carry significant meaning.\n",
    "4. **Stemming and Lemmatization**: Reducing words to their root form (stemming) or dictionary form (lemmatization).\n",
    "5. **Punctuation Removal**: Removing punctuation marks that don’t contribute to the meaning of the text.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Step-by-Step Example**\n",
    "\n",
    "Let’s take an example of sentiment analysis using a simple dataset of text reviews:\n",
    "\n",
    "| Review                                       | Sentiment |\n",
    "|----------------------------------------------|-----------|\n",
    "| \"The product is great, I love it!\"           | Positive  |\n",
    "| \"Terrible service, never coming back.\"       | Negative  |\n",
    "| \"Good quality but a bit expensive.\"          | Neutral   |\n",
    "| \"Absolutely wonderful experience, thank you!\"| Positive  |\n",
    "| \"Not worth the price.\"                       | Negative  |\n",
    "\n",
    "We will use this dataset to demonstrate the text preprocessing pipeline and then apply a machine learning model for text classification (sentiment analysis).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. **Python Code Example for Text Mining**\n",
    "\n",
    "Here’s how to preprocess text data and apply a simple classification model using Python’s `scikit-learn` and `nltk` libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download necessary resources for nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "data = {'Review': [\"The product is great, I love it!\",\n",
    "                   \"Terrible service, never coming back.\",\n",
    "                   \"Good quality but a bit expensive.\",\n",
    "                   \"Absolutely wonderful experience, thank you!\",\n",
    "                   \"Not worth the price.\"],\n",
    "        'Sentiment': ['Positive', 'Negative', 'Neutral', 'Positive', 'Negative']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenization and removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply text preprocessing to the dataset\n",
    "df['Processed_Review'] = df['Review'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Convert text to numerical features using TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['Processed_Review'])\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 5: Train a classification model (Naive Bayes)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Step 8: Make predictions for new text\n",
    "new_review = [\"This product is awful!\"]\n",
    "new_review_processed = tfidf.transform([preprocess_text(new_review[0])])\n",
    "prediction = clf.predict(new_review_processed)\n",
    "print(f'Predicted Sentiment: {prediction[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- **Step 1**: We create a dataset with text reviews and their associated sentiment labels.\n",
    "- **Step 2**: We define a function to preprocess the text (lowercasing, removing punctuation, tokenization, removing stop words, and lemmatization).\n",
    "- **Step 3**: We convert the processed text into numerical features using **TF-IDF**.\n",
    "- **Step 4**: We split the data into training and testing sets.\n",
    "- **Step 5**: We train a **Naive Bayes** classifier on the training set.\n",
    "- **Step 6**: We make predictions on the test set.\n",
    "- **Step 7**: We evaluate the accuracy of the model.\n",
    "- **Step 8**: We predict the sentiment of a new review using the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Advanced Techniques in Text Mining**\n",
    "\n",
    "1. **Word Embeddings**: Unlike TF-IDF or Bag of Words, word embeddings capture semantic relationships between words. Popular methods include **Word2Vec** and **GloVe**.\n",
    "   \n",
    "   Example: In Word2Vec, \"king\" and \"queen\" are close in the vector space, as are \"man\" and \"woman\".\n",
    "\n",
    "2. **Topic Modeling**: Extracts hidden topics from a collection of documents. **Latent Dirichlet Allocation (LDA)** is a common algorithm for topic modeling.\n",
    "\n",
    "3. **Named Entity Recognition (NER)**: Identifies and classifies named entities (e.g., people, organizations, locations) in text. This is often implemented using **SpaCy** or **nltk**.\n",
    "\n",
    "4. **Sentiment Analysis with Deep Learning**: More advanced models such as Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, or Transformers (e.g., BERT) can be used to capture context in text and improve sentiment analysis or text classification.\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **Conclusion**\n",
    "\n",
    "Text mining is a powerful tool for extracting meaningful insights from unstructured text data. It involves several techniques, from preprocessing raw text to building models for classification or sentiment analysis. Using Python libraries such as `nltk`, `scikit-learn`, and `pandas`, text mining can be efficiently implemented and applied to a wide range of applications.\n",
    "\n",
    "**Homework**:  \n",
    "- Use a larger dataset of product reviews (e.g., from Amazon or Yelp) and perform sentiment analysis.\n",
    "- Experiment with different text vectorization methods (e.g., Bag of Words vs. TF-IDF) and compare their results.\n",
    "- Try implementing topic modeling using Latent Dirichlet Allocation (LDA) and interpret the topics generated from the text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
