{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Categorical Values into Numerical ones\n",
    "## Topics and Outcomes\n",
    "\n",
    "\n",
    "When working with machine learning models, especially linear regression or most algorithms, **categorical variables** need to be converted into **numerical** ones because models usually require numeric input to compute distances, apply mathematical transformations, etc.\n",
    "\n",
    "Here are the common techniques to convert categorical variables into numerical ones, along with examples using `scikit-learn`.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. One-Hot Encoding**\n",
    "\n",
    "**One-hot encoding** creates binary (0 or 1) variables for each category. Each category gets its own column, and the value is 1 if the category is present in that sample, otherwise 0.\n",
    "\n",
    "### **Example with Scikit-Learn**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize OneHotEncoder\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Apply the encoder to the 'Product' column\u001b[39;00m\n\u001b[0;32m     12\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample dataset with a categorical variable\n",
    "data = {'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Apply the encoder to the 'Product' column\n",
    "encoded_data = encoder.fit_transform(df[['Product']])\n",
    "\n",
    "# Get the new column names from the encoder\n",
    "column_names = encoder.get_feature_names_out(['Product'])\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=column_names)\n",
    "\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Simple and effective for categories with no ordinal relationship.\n",
    "- Widely used in many machine learning models.\n",
    "\n",
    "**Cons**:\n",
    "- Can result in high dimensionality when there are many categories (curse of dimensionality).\n",
    "- Doesn't capture the relationship between categories (e.g., rank or order).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Label Encoding**\n",
    "\n",
    "**Label encoding** assigns a unique integer to each category. This method is most appropriate when the categorical variables are **ordinal** (i.e., the categories have a meaningful order).\n",
    "\n",
    "### **Example with Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample dataset with a categorical variable\n",
    "data = {'Size': ['Small', 'Medium', 'Large', 'Medium', 'Small', 'Large', 'Medium']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply the encoder to the 'Size' column\n",
    "df['Size_Encoded'] = label_encoder.fit_transform(df['Size'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Efficient and simple for ordinal variables where the order is meaningful.\n",
    "- Doesn’t increase dimensionality.\n",
    "\n",
    "**Cons**:\n",
    "- Can mislead models when used on nominal variables (no inherent order), as models might assume a ranking based on the integer labels.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Ordinal Encoding**\n",
    "\n",
    "**Ordinal encoding** is similar to label encoding but explicitly used when the categories have a natural order (like `Low < Medium < High`).\n",
    "\n",
    "### **Example with Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Sample dataset with an ordinal variable\n",
    "data = {'Education_Level': ['High School', 'Bachelor', 'Master', 'PhD']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the ordering of the categories\n",
    "education_order = [['High School', 'Bachelor', 'Master', 'PhD']]\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=education_order)\n",
    "\n",
    "# Apply the encoder to the 'Education_Level' column\n",
    "df['Education_Level_Encoded'] = ordinal_encoder.fit_transform(df[['Education_Level']])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Maintains the order of categories.\n",
    "- Works well with features that have an inherent ranking (ordinal data).\n",
    "\n",
    "**Cons**:\n",
    "- Should not be used for nominal data (no inherent order).\n",
    "- May introduce assumptions about the relationship between categories that are not accurate.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Target Encoding (Mean Encoding)**\n",
    "\n",
    "**Target encoding** replaces each category with the mean of the target variable for that category. For example, if you're predicting house prices, and the \"city\" is a categorical feature, you could replace each city with the average house price in that city.\n",
    "\n",
    "### **Example (Manual Implementation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset with categorical variable and target variable (Sales)\n",
    "data = {'City': ['CityA', 'CityB', 'CityA', 'CityC', 'CityB', 'CityA'],\n",
    "        'Sales': [200, 300, 250, 400, 320, 280]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the mean target value for each category\n",
    "city_mean_encoding = df.groupby('City')['Sales'].mean()\n",
    "\n",
    "# Apply mean encoding to the 'City' column\n",
    "df['City_Encoded'] = df['City'].map(city_mean_encoding)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Reduces dimensionality, which is beneficial for categorical variables with many unique values.\n",
    "- Captures the relationship between the categorical variable and the target variable.\n",
    "\n",
    "**Cons**:\n",
    "- Can lead to **data leakage** if not done properly, meaning the model might learn from information it wouldn't have during prediction.\n",
    "- Needs to be used carefully, especially in cross-validation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Frequency or Count Encoding**\n",
    "\n",
    "This method replaces each category with the count (or frequency) of its occurrences in the dataset. It’s useful when the distribution of categories might have an impact on the target variable.\n",
    "\n",
    "### **Example (Manual Implementation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset with a categorical variable\n",
    "data = {'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count the occurrences of each category\n",
    "product_counts = df['Product'].value_counts()\n",
    "\n",
    "# Apply count encoding to the 'Product' column\n",
    "df['Product_Encoded'] = df['Product'].map(product_counts)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Simple to implement.\n",
    "- Helps capture the impact of category frequency on the target variable.\n",
    "\n",
    "**Cons**:\n",
    "- Doesn't capture relationships between categories or their intrinsic properties.\n",
    "- Might not work well if counts don’t represent a meaningful relationship with the target.\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparison and Use Cases**\n",
    "\n",
    "| **Method**              | **Use Case**                                             | **Advantages**                              | **Disadvantages**                       |\n",
    "|-------------------------|----------------------------------------------------------|---------------------------------------------|-----------------------------------------|\n",
    "| **One-Hot Encoding**     | Nominal variables with no inherent order                 | Works well with nominal data                | Increases dimensionality                |\n",
    "| **Label Encoding**       | Ordinal variables with inherent order                    | Simple to implement                         | Misleading for nominal variables        |\n",
    "| **Ordinal Encoding**     | Ordinal variables with meaningful ranks                  | Preserves order of categories               | Assumes linear relationship             |\n",
    "| **Target Encoding**      | Categorical variables where a relationship with target exists | Can capture complex relationships            | Prone to data leakage                  |\n",
    "| **Frequency/Count Encoding** | High-cardinality categorical variables                  | Reduces dimensionality                      | May not capture category meaning        |\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Choosing the right encoding method depends on the type of categorical variable (nominal or ordinal), the relationship between the feature and target, and the characteristics of the dataset. \n",
    "\n",
    "For example:\n",
    "- **One-Hot Encoding** works best for variables with no natural order (e.g., Product types).\n",
    "- **Label or Ordinal Encoding** is useful when there's a clear order (e.g., Education levels).\n",
    "- **Target Encoding** can be helpful when a category has a strong influence on the target variable, but you need to be careful about overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1: Import Libraries and Open the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../datasets/apartment_prices.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2: One-Hot Encoding the Categorical Variable**\n",
    "\n",
    "To properly include the categorical **'Region'** feature, we need to convert it to a numerical format using **One-Hot Encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Apply the encoder to the 'City' column\n",
    "encoded_city = encoder.fit_transform(df[['City']])\n",
    "\n",
    "# Get the new column names for the encoded 'Region' variable\n",
    "city_encoded_df = pd.DataFrame(encoded_city, columns=encoder.get_feature_names_out(['City']))\n",
    "\n",
    "# Combine the original dataset with the encoded 'Region' variable\n",
    "df = pd.concat([df, city_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original 'Region' column as it's now encoded\n",
    "df = df.drop('City', axis=1)\n",
    "\n",
    "# Display the updated DataFrame with one-hot encoded regions\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3: Define Features and Target Including the Encoded Variables**\n",
    "\n",
    "Now, the dataset includes the **one-hot encoded** region columns along with the original advertising spend features. We will include these encoded columns in our feature set for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Target\n",
    "X = df[['Square_Area', 'Num_Rooms', 'Age_of_Building','Floor_Level','City_Amman','City_Irbid','City_Aqaba']]  # Independent variables\n",
    "y = df['Price']  # Dependent variable (Sales)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4: Train the Model**\n",
    "\n",
    "We can now train the model using the expanded feature set, which includes both numerical and the one-hot encoded categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Coefficients and Intercept\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5: Make Predictions and Evaluate the Model**\n",
    "\n",
    "Evaluate the model's performance using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE, MAE, and R²\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,2))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,2))\n",
    "print(\"R-squared (R²):\", round(r2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6: Visualizing Performance**\n",
    "\n",
    "Finally, we can plot the actual vs predicted values to visualize the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.scatter(y_test, y_pred, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)  # Line of perfect fit\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Impact of Including the Categorical Variable**\n",
    "\n",
    "The inclusion of the **Region** variable can improve the model’s performance, as sales might differ depending on the geographical location. By **one-hot encoding** the region, we allow the model to account for differences in sales patterns across regions.\n",
    "\n",
    "#### **Summary**\n",
    "\n",
    "- We added a **categorical variable** (\"Region\") to represent different geographical areas.\n",
    "- We used **One-Hot Encoding** to convert the categorical variable into a numerical format that the linear regression model can handle.\n",
    "- The expanded feature set now includes advertising spend and the encoded region, allowing the model to capture regional variations in sales.\n",
    "\n",
    "By including this additional categorical feature, the model has the potential to **improve accuracy** since regional differences might play an important role in influencing sales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
