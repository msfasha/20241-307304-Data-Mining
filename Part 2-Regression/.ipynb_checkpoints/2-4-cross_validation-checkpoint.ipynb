{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcc2912-e84e-440c-b315-60d18ab756dd",
   "metadata": {},
   "source": [
    "Cross-validation is a technique used to evaluate a machine learning modelâ€™s performance by training and testing it on different subsets of a dataset. Instead of evaluating the model on a single train-test split, cross-validation helps ensure that the model performs well on unseen data and is not overfitting or underfitting.\n",
    "\n",
    "### Why Use Cross-Validation?\n",
    "\n",
    "1. **Improves Model Reliability**: By testing on multiple subsets, you get a more reliable estimate of how well the model will generalize to new data.\n",
    "2. **Reduces Overfitting**: Helps prevent overfitting by ensuring the model performs well across different data splits.\n",
    "3. **Optimizes Parameter Tuning**: Often used with hyperparameter tuning to find the best configuration.\n",
    "\n",
    "### How Cross-Validation Works\n",
    "\n",
    "The dataset is split into multiple subsets, called \"folds.\" The model is trained on all but one fold and tested on the remaining fold. This process is repeated, with each fold used once as the test set. The performance metric (like accuracy or MSE) is averaged over all folds.\n",
    "\n",
    "### Types of Cross-Validation\n",
    "\n",
    "1. **K-Fold Cross-Validation**:\n",
    "   - Divides the data into `k` equally sized folds (e.g., 5 or 10).\n",
    "   - The model is trained on `k-1` folds and tested on the remaining fold.\n",
    "   - This process repeats `k` times, using a different fold as the test set each time.\n",
    "   - **Example**: For 5-fold cross-validation, the data is split into 5 parts. The model is trained on 4 parts and tested on the remaining part. This repeats five times, with each part being the test set once.\n",
    "\n",
    "2. **Stratified K-Fold Cross-Validation**:\n",
    "   - Similar to K-Fold, but preserves the class distribution in each fold (useful for imbalanced datasets).\n",
    "   - Ensures each fold has approximately the same percentage of each target class as the entire dataset.\n",
    "\n",
    "3. **Leave-One-Out Cross-Validation (LOOCV)**:\n",
    "   - Each instance in the dataset is used once as the test set and the rest as the training set.\n",
    "   - Ideal for small datasets, but computationally expensive for large datasets.\n",
    "\n",
    "4. **Time Series Split**:\n",
    "   - Used for time-dependent data (e.g., stock prices, weather data).\n",
    "   - Ensures training data always precedes testing data to avoid data leakage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c0632-fad9-4b5f-9d37-ef9f5f507725",
   "metadata": {},
   "source": [
    "### Example with K-Fold Cross-Validation in `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0549938-b110-4138-8ef3-dfb50e0cdcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.96666667 0.96666667 0.93333333 0.9        1.        ]\n",
      "Average Accuracy: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load example dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)  # cv=5 for 5 folds\n",
    "\n",
    "# Print average score\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab6c8c-2169-433b-8fd9-b674deb81956",
   "metadata": {},
   "source": [
    "Here, `cross_val_score` will train and test the model on each fold, returning a score for each iteration. The average score gives a good measure of model performance.\n",
    "\n",
    "Cross-validation is a fundamental technique in machine learning, especially when you want to assess how well a model will generalize to unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
